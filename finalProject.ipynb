{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "2e4d6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import Adam, SGD\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210ded1b",
   "metadata": {},
   "source": [
    "## import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "072c42fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance\\t</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4419</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4420</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9147</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>152.0</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4424 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Marital status  Application mode  Application order  Course  \\\n",
       "0                  1                17                  5     171   \n",
       "1                  1                15                  1    9254   \n",
       "2                  1                 1                  5    9070   \n",
       "3                  1                17                  2    9773   \n",
       "4                  2                39                  1    8014   \n",
       "...              ...               ...                ...     ...   \n",
       "4419               1                 1                  6    9773   \n",
       "4420               1                 1                  2    9773   \n",
       "4421               1                 1                  1    9500   \n",
       "4422               1                 1                  1    9147   \n",
       "4423               1                10                  1    9773   \n",
       "\n",
       "      Daytime/evening attendance\\t  Previous qualification  \\\n",
       "0                                1                       1   \n",
       "1                                1                       1   \n",
       "2                                1                       1   \n",
       "3                                1                       1   \n",
       "4                                0                       1   \n",
       "...                            ...                     ...   \n",
       "4419                             1                       1   \n",
       "4420                             1                       1   \n",
       "4421                             1                       1   \n",
       "4422                             1                       1   \n",
       "4423                             1                       1   \n",
       "\n",
       "      Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                              122.0            1                      19   \n",
       "1                              160.0            1                       1   \n",
       "2                              122.0            1                      37   \n",
       "3                              122.0            1                      38   \n",
       "4                              100.0            1                      37   \n",
       "...                              ...          ...                     ...   \n",
       "4419                           125.0            1                       1   \n",
       "4420                           120.0          105                       1   \n",
       "4421                           154.0            1                      37   \n",
       "4422                           180.0            1                      37   \n",
       "4423                           152.0           22                      38   \n",
       "\n",
       "      Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
       "0                         12  ...                                    0   \n",
       "1                          3  ...                                    0   \n",
       "2                         37  ...                                    0   \n",
       "3                         37  ...                                    0   \n",
       "4                         38  ...                                    0   \n",
       "...                      ...  ...                                  ...   \n",
       "4419                       1  ...                                    0   \n",
       "4420                       1  ...                                    0   \n",
       "4421                      37  ...                                    0   \n",
       "4422                      37  ...                                    0   \n",
       "4423                      37  ...                                    0   \n",
       "\n",
       "      Curricular units 2nd sem (enrolled)  \\\n",
       "0                                       0   \n",
       "1                                       6   \n",
       "2                                       6   \n",
       "3                                       6   \n",
       "4                                       6   \n",
       "...                                   ...   \n",
       "4419                                    6   \n",
       "4420                                    6   \n",
       "4421                                    8   \n",
       "4422                                    5   \n",
       "4423                                    6   \n",
       "\n",
       "      Curricular units 2nd sem (evaluations)  \\\n",
       "0                                          0   \n",
       "1                                          6   \n",
       "2                                          0   \n",
       "3                                         10   \n",
       "4                                          6   \n",
       "...                                      ...   \n",
       "4419                                       8   \n",
       "4420                                       6   \n",
       "4421                                       9   \n",
       "4422                                       6   \n",
       "4423                                       6   \n",
       "\n",
       "      Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                       0                          0.000000   \n",
       "1                                       6                         13.666667   \n",
       "2                                       0                          0.000000   \n",
       "3                                       5                         12.400000   \n",
       "4                                       6                         13.000000   \n",
       "...                                   ...                               ...   \n",
       "4419                                    5                         12.666667   \n",
       "4420                                    2                         11.000000   \n",
       "4421                                    1                         13.500000   \n",
       "4422                                    5                         12.000000   \n",
       "4423                                    6                         13.000000   \n",
       "\n",
       "      Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                                  0               10.8   \n",
       "1                                                  0               13.9   \n",
       "2                                                  0               10.8   \n",
       "3                                                  0                9.4   \n",
       "4                                                  0               13.9   \n",
       "...                                              ...                ...   \n",
       "4419                                               0               15.5   \n",
       "4420                                               0               11.1   \n",
       "4421                                               0               13.9   \n",
       "4422                                               0                9.4   \n",
       "4423                                               0               12.7   \n",
       "\n",
       "      Inflation rate   GDP    Target  \n",
       "0                1.4  1.74   Dropout  \n",
       "1               -0.3  0.79  Graduate  \n",
       "2                1.4  1.74   Dropout  \n",
       "3               -0.8 -3.12  Graduate  \n",
       "4               -0.3  0.79  Graduate  \n",
       "...              ...   ...       ...  \n",
       "4419             2.8 -4.06  Graduate  \n",
       "4420             0.6  2.02   Dropout  \n",
       "4421            -0.3  0.79   Dropout  \n",
       "4422            -0.8 -3.12  Graduate  \n",
       "4423             3.7 -1.70  Graduate  \n",
       "\n",
       "[4424 rows x 37 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students = pd.read_csv('students/student.csv', sep = ';')\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1e089a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_wine = pd.read_csv('wine/winequality-white.csv', sep=';')\n",
    "white_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0b5166f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.64.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.45</th>\n",
       "      <th>3.756</th>\n",
       "      <th>61</th>\n",
       "      <th>278</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...   0.41  \\\n",
       "0     0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.000   \n",
       "1     0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.010   \n",
       "2     0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "3     0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "4     0.00  0.00    0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00  ...  0.000   \n",
       "...    ...   ...     ...  ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
       "4595  0.31  0.00    0.62  0.0  0.00  0.31  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4596  0.00  0.00    0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4597  0.30  0.00    0.30  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.102   \n",
       "4598  0.96  0.00    0.00  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4599  0.00  0.00    0.65  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "\n",
       "       0.42  0.43  0.778   0.44   0.45  3.756   61   278  1  \n",
       "0     0.132   0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
       "1     0.143   0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
       "2     0.137   0.0  0.137  0.000  0.000  3.537   40   191  1  \n",
       "3     0.135   0.0  0.135  0.000  0.000  3.537   40   191  1  \n",
       "4     0.223   0.0  0.000  0.000  0.000  3.000   15    54  1  \n",
       "...     ...   ...    ...    ...    ...    ...  ...   ... ..  \n",
       "4595  0.232   0.0  0.000  0.000  0.000  1.142    3    88  0  \n",
       "4596  0.000   0.0  0.353  0.000  0.000  1.555    4    14  0  \n",
       "4597  0.718   0.0  0.000  0.000  0.000  1.404    6   118  0  \n",
       "4598  0.057   0.0  0.000  0.000  0.000  1.147    5    78  0  \n",
       "4599  0.000   0.0  0.125  0.000  0.000  1.250    5    40  0  \n",
       "\n",
       "[4600 rows x 58 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = pd.read_csv('spam/spambase.data')\n",
    "spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1388f0cb",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "55ac8980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "Graduate    2209\n",
       "Dropout     1421\n",
       "Enrolled     794\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a3a53291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance\\t</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4419</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4420</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9147</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>152.0</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3630 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Marital status  Application mode  Application order  Course  \\\n",
       "0                  1                17                  5     171   \n",
       "1                  1                15                  1    9254   \n",
       "2                  1                 1                  5    9070   \n",
       "3                  1                17                  2    9773   \n",
       "4                  2                39                  1    8014   \n",
       "...              ...               ...                ...     ...   \n",
       "4419               1                 1                  6    9773   \n",
       "4420               1                 1                  2    9773   \n",
       "4421               1                 1                  1    9500   \n",
       "4422               1                 1                  1    9147   \n",
       "4423               1                10                  1    9773   \n",
       "\n",
       "      Daytime/evening attendance\\t  Previous qualification  \\\n",
       "0                                1                       1   \n",
       "1                                1                       1   \n",
       "2                                1                       1   \n",
       "3                                1                       1   \n",
       "4                                0                       1   \n",
       "...                            ...                     ...   \n",
       "4419                             1                       1   \n",
       "4420                             1                       1   \n",
       "4421                             1                       1   \n",
       "4422                             1                       1   \n",
       "4423                             1                       1   \n",
       "\n",
       "      Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                              122.0            1                      19   \n",
       "1                              160.0            1                       1   \n",
       "2                              122.0            1                      37   \n",
       "3                              122.0            1                      38   \n",
       "4                              100.0            1                      37   \n",
       "...                              ...          ...                     ...   \n",
       "4419                           125.0            1                       1   \n",
       "4420                           120.0          105                       1   \n",
       "4421                           154.0            1                      37   \n",
       "4422                           180.0            1                      37   \n",
       "4423                           152.0           22                      38   \n",
       "\n",
       "      Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
       "0                         12  ...                                    0   \n",
       "1                          3  ...                                    0   \n",
       "2                         37  ...                                    0   \n",
       "3                         37  ...                                    0   \n",
       "4                         38  ...                                    0   \n",
       "...                      ...  ...                                  ...   \n",
       "4419                       1  ...                                    0   \n",
       "4420                       1  ...                                    0   \n",
       "4421                      37  ...                                    0   \n",
       "4422                      37  ...                                    0   \n",
       "4423                      37  ...                                    0   \n",
       "\n",
       "      Curricular units 2nd sem (enrolled)  \\\n",
       "0                                       0   \n",
       "1                                       6   \n",
       "2                                       6   \n",
       "3                                       6   \n",
       "4                                       6   \n",
       "...                                   ...   \n",
       "4419                                    6   \n",
       "4420                                    6   \n",
       "4421                                    8   \n",
       "4422                                    5   \n",
       "4423                                    6   \n",
       "\n",
       "      Curricular units 2nd sem (evaluations)  \\\n",
       "0                                          0   \n",
       "1                                          6   \n",
       "2                                          0   \n",
       "3                                         10   \n",
       "4                                          6   \n",
       "...                                      ...   \n",
       "4419                                       8   \n",
       "4420                                       6   \n",
       "4421                                       9   \n",
       "4422                                       6   \n",
       "4423                                       6   \n",
       "\n",
       "      Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                       0                          0.000000   \n",
       "1                                       6                         13.666667   \n",
       "2                                       0                          0.000000   \n",
       "3                                       5                         12.400000   \n",
       "4                                       6                         13.000000   \n",
       "...                                   ...                               ...   \n",
       "4419                                    5                         12.666667   \n",
       "4420                                    2                         11.000000   \n",
       "4421                                    1                         13.500000   \n",
       "4422                                    5                         12.000000   \n",
       "4423                                    6                         13.000000   \n",
       "\n",
       "      Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                                  0               10.8   \n",
       "1                                                  0               13.9   \n",
       "2                                                  0               10.8   \n",
       "3                                                  0                9.4   \n",
       "4                                                  0               13.9   \n",
       "...                                              ...                ...   \n",
       "4419                                               0               15.5   \n",
       "4420                                               0               11.1   \n",
       "4421                                               0               13.9   \n",
       "4422                                               0                9.4   \n",
       "4423                                               0               12.7   \n",
       "\n",
       "      Inflation rate   GDP    Target  \n",
       "0                1.4  1.74   Dropout  \n",
       "1               -0.3  0.79  Graduate  \n",
       "2                1.4  1.74   Dropout  \n",
       "3               -0.8 -3.12  Graduate  \n",
       "4               -0.3  0.79  Graduate  \n",
       "...              ...   ...       ...  \n",
       "4419             2.8 -4.06  Graduate  \n",
       "4420             0.6  2.02   Dropout  \n",
       "4421            -0.3  0.79   Dropout  \n",
       "4422            -0.8 -3.12  Graduate  \n",
       "4423             3.7 -1.70  Graduate  \n",
       "\n",
       "[3630 rows x 37 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students = students[students['Target'] != 'Enrolled']\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "39efdc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance\\t</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4419</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4420</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9147</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>152.0</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3630 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Marital status  Application mode  Application order  Course  \\\n",
       "0                  1                17                  5     171   \n",
       "1                  1                15                  1    9254   \n",
       "2                  1                 1                  5    9070   \n",
       "3                  1                17                  2    9773   \n",
       "4                  2                39                  1    8014   \n",
       "...              ...               ...                ...     ...   \n",
       "4419               1                 1                  6    9773   \n",
       "4420               1                 1                  2    9773   \n",
       "4421               1                 1                  1    9500   \n",
       "4422               1                 1                  1    9147   \n",
       "4423               1                10                  1    9773   \n",
       "\n",
       "      Daytime/evening attendance\\t  Previous qualification  \\\n",
       "0                                1                       1   \n",
       "1                                1                       1   \n",
       "2                                1                       1   \n",
       "3                                1                       1   \n",
       "4                                0                       1   \n",
       "...                            ...                     ...   \n",
       "4419                             1                       1   \n",
       "4420                             1                       1   \n",
       "4421                             1                       1   \n",
       "4422                             1                       1   \n",
       "4423                             1                       1   \n",
       "\n",
       "      Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                              122.0            1                      19   \n",
       "1                              160.0            1                       1   \n",
       "2                              122.0            1                      37   \n",
       "3                              122.0            1                      38   \n",
       "4                              100.0            1                      37   \n",
       "...                              ...          ...                     ...   \n",
       "4419                           125.0            1                       1   \n",
       "4420                           120.0          105                       1   \n",
       "4421                           154.0            1                      37   \n",
       "4422                           180.0            1                      37   \n",
       "4423                           152.0           22                      38   \n",
       "\n",
       "      Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
       "0                         12  ...                                    0   \n",
       "1                          3  ...                                    0   \n",
       "2                         37  ...                                    0   \n",
       "3                         37  ...                                    0   \n",
       "4                         38  ...                                    0   \n",
       "...                      ...  ...                                  ...   \n",
       "4419                       1  ...                                    0   \n",
       "4420                       1  ...                                    0   \n",
       "4421                      37  ...                                    0   \n",
       "4422                      37  ...                                    0   \n",
       "4423                      37  ...                                    0   \n",
       "\n",
       "      Curricular units 2nd sem (enrolled)  \\\n",
       "0                                       0   \n",
       "1                                       6   \n",
       "2                                       6   \n",
       "3                                       6   \n",
       "4                                       6   \n",
       "...                                   ...   \n",
       "4419                                    6   \n",
       "4420                                    6   \n",
       "4421                                    8   \n",
       "4422                                    5   \n",
       "4423                                    6   \n",
       "\n",
       "      Curricular units 2nd sem (evaluations)  \\\n",
       "0                                          0   \n",
       "1                                          6   \n",
       "2                                          0   \n",
       "3                                         10   \n",
       "4                                          6   \n",
       "...                                      ...   \n",
       "4419                                       8   \n",
       "4420                                       6   \n",
       "4421                                       9   \n",
       "4422                                       6   \n",
       "4423                                       6   \n",
       "\n",
       "      Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                       0                          0.000000   \n",
       "1                                       6                         13.666667   \n",
       "2                                       0                          0.000000   \n",
       "3                                       5                         12.400000   \n",
       "4                                       6                         13.000000   \n",
       "...                                   ...                               ...   \n",
       "4419                                    5                         12.666667   \n",
       "4420                                    2                         11.000000   \n",
       "4421                                    1                         13.500000   \n",
       "4422                                    5                         12.000000   \n",
       "4423                                    6                         13.000000   \n",
       "\n",
       "      Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                                  0               10.8   \n",
       "1                                                  0               13.9   \n",
       "2                                                  0               10.8   \n",
       "3                                                  0                9.4   \n",
       "4                                                  0               13.9   \n",
       "...                                              ...                ...   \n",
       "4419                                               0               15.5   \n",
       "4420                                               0               11.1   \n",
       "4421                                               0               13.9   \n",
       "4422                                               0                9.4   \n",
       "4423                                               0               12.7   \n",
       "\n",
       "      Inflation rate   GDP  Target  \n",
       "0                1.4  1.74       1  \n",
       "1               -0.3  0.79       0  \n",
       "2                1.4  1.74       1  \n",
       "3               -0.8 -3.12       0  \n",
       "4               -0.3  0.79       0  \n",
       "...              ...   ...     ...  \n",
       "4419             2.8 -4.06       0  \n",
       "4420             0.6  2.02       1  \n",
       "4421            -0.3  0.79       1  \n",
       "4422            -0.8 -3.12       0  \n",
       "4423             3.7 -1.70       0  \n",
       "\n",
       "[3630 rows x 37 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students = students.copy()\n",
    "students['Target'] = students['Target'].apply(lambda x: 0 if x == 'Graduate' else 1)\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e62da7",
   "metadata": {},
   "source": [
    "## white_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3916d700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 7, 8, 4, 3, 9], dtype=int64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_wine['quality'].unique() # ranges from 3-9, make it good quality if above 6, 7-9 = good, 3-6 = bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fca12353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  Target  \n",
       "0         8.8        6       1  \n",
       "1         9.5        6       1  \n",
       "2        10.1        6       1  \n",
       "3         9.9        6       1  \n",
       "4         9.9        6       1  \n",
       "...       ...      ...     ...  \n",
       "4893     11.2        6       1  \n",
       "4894      9.6        5       0  \n",
       "4895      9.4        6       1  \n",
       "4896     12.8        7       1  \n",
       "4897     11.8        6       1  \n",
       "\n",
       "[4898 rows x 13 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 for bad wine, [3,4,5,6] quality, and 1 for good wine [7,8,9] quality\n",
    "white_wine['Target'] = white_wine['quality'].apply(lambda x: 1 if x > 5 else 0)\n",
    "white_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ade2f168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "1    3258\n",
       "0    1640\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_wine['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e664318a",
   "metadata": {},
   "source": [
    "### spam preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ba2a9965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\n",
       "0    2788\n",
       "1    1812\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam['1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c7eab8",
   "metadata": {},
   "source": [
    "## Find hyper parameter for random forest, svm, and neural network using white wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "79532505",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wine_X = white_wine.drop('Target', axis = 1)\n",
    "white_wine_Y = white_wine['Target']\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train_all, X_test, y_train_all, y_test = train_test_split(white_wine_X, white_wine_Y, test_size=0.2)\n",
    "\n",
    "# Fit StandardScaler only on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_all = scaler.fit_transform(X_train_all)\n",
    "\n",
    "# Transform test data with the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cfaf77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the parameter grid according to the research paper - caruna\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [1024],\n",
    "    'max_features': [1, 2, 4, 6, 8, 12, 16, 20]\n",
    "}\n",
    "\n",
    "# too long\n",
    "# param_grid_svm = {\n",
    "#     'C': np.logspace(-7, 3, num=11),  # Creates a sequence from 10^-7 to 10^3\n",
    "#     'kernel': ['linear', 'poly', 'rbf'],\n",
    "#     'degree': [2, 3],\n",
    "#     'gamma': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2]\n",
    "# }\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],  # Reduced range\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1]  # Streamlined values\n",
    "}\n",
    "\n",
    "param_grid_nn = {\n",
    "    'model__hidden_units': [1, 2, 4, 8, 32, 128],\n",
    "    'model__momentum': [0, 0.2, 0.5, 0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986e0b61",
   "metadata": {},
   "source": [
    "Since the param_grid_svsm is taking way too long, i decided to use simplified version of hyper parameter tuning options for **svm** from that of research paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f5d28448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_features': 1, 'n_estimators': 1024}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search_rf.fit(X_train_scaled_all, y_train_all)\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "best_params_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9bb673c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.2s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.2s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.4s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.4s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.4s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.4s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.4s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.2s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.2s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.5s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.5s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.5s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.6s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.6s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.2s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.3s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.2s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.5s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.5s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.5s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.5s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.5s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.2s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.2s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.5s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.5s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.6s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.5s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'gamma': 0.001, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC()\n",
    "grid_search_svm = GridSearchCV(estimator=svm_model, param_grid=param_grid_svm, cv=5, verbose=2)\n",
    "grid_search_svm.fit(X_train_scaled_all, y_train_all)\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "best_params_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9401c9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__hidden_units': 2, 'model__momentum': 0.9}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_model(**kwargs):\n",
    "    hidden_units = kwargs.get('hidden_units', 32)  # Default value as fallback\n",
    "    momentum = kwargs.get('momentum', 0.0)  # Default value as fallback\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=X_train_scaled_all.shape[1],))\n",
    "    model.add(Dense(hidden_units, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = SGD(momentum=momentum)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "nn = KerasClassifier(model=create_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "grid_search_nn = GridSearchCV(estimator=nn, param_grid=param_grid_nn, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search_nn.fit(X_train_scaled_all, y_train_all)\n",
    "\n",
    "best_params_nn = grid_search_nn.best_params_\n",
    "best_params_nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dffa24",
   "metadata": {},
   "source": [
    "### feed in to models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "51686708",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wine_X = white_wine.drop('Target', axis = 1)\n",
    "white_wine_Y = white_wine['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b176e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding to 80/20, 50/50, 20/80 splits\n",
    "partitions = [0.2, 0.5, 0.8]\n",
    "num_trials = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0274d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and test sets\n",
    "X_train_all, X_test, y_train_all, y_test = train_test_split(white_wine_X, white_wine_Y, test_size=0.2)\n",
    "\n",
    "# Fit StandardScaler only on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_all = scaler.fit_transform(X_train_all)\n",
    "\n",
    "# Transform test data with the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0700c8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition 0.2 Results:\n",
      "  Random Forest - Train Accuracy: 1.0, Val Accuracy: 1.0, Test Accuracy: 1.0\n",
      "  SVM - Train Accuracy: 1.0, Val Accuracy: 1.0, Test Accuracy: 1.0\n",
      "  Neural Network - Train Accuracy: 0.9963837663332621, Val Accuracy: 0.9970238010088602, Test Accuracy: 0.9972789287567139\n",
      "Partition 0.5 Results:\n",
      "  Random Forest - Train Accuracy: 1.0, Val Accuracy: 1.0, Test Accuracy: 1.0\n",
      "  SVM - Train Accuracy: 1.0, Val Accuracy: 1.0, Test Accuracy: 1.0\n",
      "  Neural Network - Train Accuracy: 0.9700527588526408, Val Accuracy: 0.9632465442021688, Test Accuracy: 0.9680272142092387\n",
      "Partition 0.8 Results:\n",
      "  Random Forest - Train Accuracy: 1.0, Val Accuracy: 0.9990430622009571, Test Accuracy: 0.9996598639455782\n",
      "  SVM - Train Accuracy: 1.0, Val Accuracy: 1.0, Test Accuracy: 1.0\n",
      "  Neural Network - Train Accuracy: 0.8795231978098551, Val Accuracy: 0.8575225869814554, Test Accuracy: 0.8649659951527914\n"
     ]
    }
   ],
   "source": [
    "for partition in partitions:\n",
    "    rf_train_accuracies, rf_val_accuracies, rf_test_accuracies = [], [], []\n",
    "    svm_train_accuracies, svm_val_accuracies, svm_test_accuracies = [], [], []\n",
    "    nn_train_accuracies, nn_val_accuracies, nn_test_accuracies = [], [], []\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        X_train_scaled, X_val_scaled, y_train, y_val = train_test_split(X_train_scaled_all, y_train_all, test_size=partition)\n",
    "        \n",
    "        # Random Forest\n",
    "        rf_model = RandomForestClassifier(**best_params_rf, verbose = 0)\n",
    "        rf_model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        rf_train_accuracy = rf_model.score(X_train_scaled, y_train)\n",
    "        rf_val_accuracy = rf_model.score(X_val_scaled, y_val)\n",
    "        rf_test_accuracy = rf_model.score(X_test_scaled, y_test)\n",
    "        \n",
    "        rf_train_accuracies.append(rf_train_accuracy)\n",
    "        rf_val_accuracies.append(rf_val_accuracy)\n",
    "        rf_test_accuracies.append(rf_test_accuracy)\n",
    "\n",
    "        # SVM\n",
    "        svm_model = SVC(**best_params_svm, probability = True)\n",
    "        svm_model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        svm_train_accuracy = svm_model.score(X_train_scaled, y_train)\n",
    "        svm_val_accuracy = svm_model.score(X_val_scaled, y_val)\n",
    "        svm_test_accuracy = svm_model.score(X_test_scaled, y_test)\n",
    "        \n",
    "        svm_train_accuracies.append(svm_train_accuracy)\n",
    "        svm_val_accuracies.append(svm_val_accuracy)\n",
    "        svm_test_accuracies.append(svm_test_accuracy)\n",
    "\n",
    "        # Neural Network\n",
    "        nn_model = create_model(**best_params_nn)\n",
    "        nn_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "        nn_model.fit(X_train_scaled, y_train, epochs = 5, batch_size = 32, verbose = 0)\n",
    "        \n",
    "        nn_loss_train, nn_accuracy_train = nn_model.evaluate(X_train_scaled, y_train, verbose = 0)\n",
    "        nn_loss_val, nn_accuracy_val = nn_model.evaluate(X_val_scaled, y_val, verbose = 0)\n",
    "        nn_loss_test, nn_accuracy_test = nn_model.evaluate(X_test_scaled, y_test, verbose = 0)\n",
    "        \n",
    "        nn_train_accuracies.append(nn_accuracy_train)\n",
    "        nn_val_accuracies.append(nn_accuracy_val)\n",
    "        nn_test_accuracies.append(nn_accuracy_test)\n",
    "\n",
    "    # Calculate mean accuracies for Random Forest\n",
    "    rf_mean_train_accuracy = np.mean(rf_train_accuracies)\n",
    "    rf_mean_val_accuracy = np.mean(rf_val_accuracies)\n",
    "    rf_mean_test_accuracy = np.mean(rf_test_accuracies)\n",
    "\n",
    "    # Calculate mean accuracies for SVM\n",
    "    svm_mean_train_accuracy = np.mean(svm_train_accuracies)\n",
    "    svm_mean_val_accuracy = np.mean(svm_val_accuracies)\n",
    "    svm_mean_test_accuracy = np.mean(svm_test_accuracies)\n",
    "\n",
    "    # Calculate mean accuracies for Neural Network\n",
    "    nn_mean_train_accuracy = np.mean(nn_train_accuracies)\n",
    "    nn_mean_val_accuracy = np.mean(nn_val_accuracies)\n",
    "    nn_mean_test_accuracy = np.mean(nn_test_accuracies)\n",
    "\n",
    "    # Print the results in an organized manner\n",
    "    print(f\"Partition {partition} Results:\")\n",
    "    print(f\"  Random Forest - Train Accuracy: {rf_mean_train_accuracy}, Val Accuracy: {rf_mean_val_accuracy}, Test Accuracy: {rf_mean_test_accuracy}\")\n",
    "    print(f\"  SVM - Train Accuracy: {svm_mean_train_accuracy}, Val Accuracy: {svm_mean_val_accuracy}, Test Accuracy: {svm_mean_test_accuracy}\")\n",
    "    print(f\"  Neural Network - Train Accuracy: {nn_mean_train_accuracy}, Val Accuracy: {nn_mean_val_accuracy}, Test Accuracy: {nn_mean_test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3959c5",
   "metadata": {},
   "source": [
    "## students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dd6dc5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_X = students.drop('Target', axis =1)\n",
    "students_y = students['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ead8b781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and test sets\n",
    "X_train_all, X_test, y_train_all, y_test = train_test_split(students_X, students_y, test_size=0.2)\n",
    "\n",
    "# Fit StandardScaler only on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_all = scaler.fit_transform(X_train_all)\n",
    "\n",
    "# Transform test data with the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fca15e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition 0.2 Results:\n",
      "  Random Forest - Train Accuracy: 1.0, Val Accuracy: 0.8973034997131383, Test Accuracy: 0.9026629935720845\n",
      "  SVM - Train Accuracy: 0.9150523748026976, Val Accuracy: 0.9030407343660355, Test Accuracy: 0.9187327823691461\n",
      "  Neural Network - Train Accuracy: 0.9104606111844381, Val Accuracy: 0.9053356250127157, Test Accuracy: 0.8925619920094808\n",
      "Partition 0.5 Results:\n",
      "  Random Forest - Train Accuracy: 1.0, Val Accuracy: 0.8957759412304868, Test Accuracy: 0.8939393939393939\n",
      "  SVM - Train Accuracy: 0.9178145087235996, Val Accuracy: 0.9067952249770431, Test Accuracy: 0.9123048668503214\n",
      "  Neural Network - Train Accuracy: 0.8994490305582682, Val Accuracy: 0.8870523373285929, Test Accuracy: 0.8778696060180664\n",
      "Partition 0.8 Results:\n",
      "  Random Forest - Train Accuracy: 1.0, Val Accuracy: 0.8878370625358577, Test Accuracy: 0.8879706152433425\n",
      "  SVM - Train Accuracy: 0.9224137931034483, Val Accuracy: 0.8964429145152036, Test Accuracy: 0.9054178145087236\n",
      "  Neural Network - Train Accuracy: 0.8534482717514038, Val Accuracy: 0.8390705585479736, Test Accuracy: 0.810835619767507\n"
     ]
    }
   ],
   "source": [
    "for partition in partitions:\n",
    "    rf_train_accuracies, rf_val_accuracies, rf_test_accuracies = [], [], []\n",
    "    svm_train_accuracies, svm_val_accuracies, svm_test_accuracies = [], [], []\n",
    "    nn_train_accuracies, nn_val_accuracies, nn_test_accuracies = [], [], []\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        \n",
    "        X_train_scaled, X_val_scaled, y_train, y_val = train_test_split(X_train_scaled_all, y_train_all, test_size=partition)\n",
    "\n",
    "        # Random Forest\n",
    "        rf_model = RandomForestClassifier(**best_params_rf, verbose = 0)\n",
    "        rf_model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        rf_train_accuracy = rf_model.score(X_train_scaled, y_train)\n",
    "        rf_val_accuracy = rf_model.score(X_val_scaled, y_val)\n",
    "        rf_test_accuracy = rf_model.score(X_test_scaled, y_test)\n",
    "        \n",
    "        rf_train_accuracies.append(rf_train_accuracy)\n",
    "        rf_val_accuracies.append(rf_val_accuracy)\n",
    "        rf_test_accuracies.append(rf_test_accuracy)\n",
    "\n",
    "        # SVM\n",
    "        svm_model = SVC(**best_params_svm, probability = True)\n",
    "        svm_model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        svm_train_accuracy = svm_model.score(X_train_scaled, y_train)\n",
    "        svm_val_accuracy = svm_model.score(X_val_scaled, y_val)\n",
    "        svm_test_accuracy = svm_model.score(X_test_scaled, y_test)\n",
    "        \n",
    "        svm_train_accuracies.append(svm_train_accuracy)\n",
    "        svm_val_accuracies.append(svm_val_accuracy)\n",
    "        svm_test_accuracies.append(svm_test_accuracy)\n",
    "\n",
    "        # Neural Network\n",
    "        nn_model = create_model(**best_params_nn)\n",
    "        nn_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "        nn_model.fit(X_train_scaled, y_train, epochs = 5, batch_size = 32, verbose = 0)\n",
    "        \n",
    "        nn_loss_train, nn_accuracy_train = nn_model.evaluate(X_train_scaled, y_train, verbose = 0)\n",
    "        nn_loss_val, nn_accuracy_val = nn_model.evaluate(X_val_scaled, y_val, verbose = 0)\n",
    "        nn_loss_test, nn_accuracy_test = nn_model.evaluate(X_test_scaled, y_test, verbose = 0)\n",
    "        \n",
    "        nn_train_accuracies.append(nn_accuracy_train)\n",
    "        nn_val_accuracies.append(nn_accuracy_val)\n",
    "        nn_test_accuracies.append(nn_accuracy_test)\n",
    "        \n",
    "    # Calculate mean accuracies for Random Forest\n",
    "    rf_mean_train_accuracy = np.mean(rf_train_accuracies)\n",
    "    rf_mean_val_accuracy = np.mean(rf_val_accuracies)\n",
    "    rf_mean_test_accuracy = np.mean(rf_test_accuracies)\n",
    "\n",
    "    # Calculate mean accuracies for SVM\n",
    "    svm_mean_train_accuracy = np.mean(svm_train_accuracies)\n",
    "    svm_mean_val_accuracy = np.mean(svm_val_accuracies)\n",
    "    svm_mean_test_accuracy = np.mean(svm_test_accuracies)\n",
    "\n",
    "    # Calculate mean accuracies for Neural Network\n",
    "    nn_mean_train_accuracy = np.mean(nn_train_accuracies)\n",
    "    nn_mean_val_accuracy = np.mean(nn_val_accuracies)\n",
    "    nn_mean_test_accuracy = np.mean(nn_test_accuracies)\n",
    "\n",
    "    # Print the results in an organized manner\n",
    "    print(f\"Partition {partition} Results:\")\n",
    "    print(f\"  Random Forest - Train Accuracy: {rf_mean_train_accuracy}, Val Accuracy: {rf_mean_val_accuracy}, Test Accuracy: {rf_mean_test_accuracy}\")\n",
    "    print(f\"  SVM - Train Accuracy: {svm_mean_train_accuracy}, Val Accuracy: {svm_mean_val_accuracy}, Test Accuracy: {svm_mean_test_accuracy}\")\n",
    "    print(f\"  Neural Network - Train Accuracy: {nn_mean_train_accuracy}, Val Accuracy: {nn_mean_val_accuracy}, Test Accuracy: {nn_mean_test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef34457",
   "metadata": {},
   "source": [
    "## spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6b144b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_X = spam.drop('1', axis =1)\n",
    "spam_y = spam['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a2009c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and test sets\n",
    "X_train_all, X_test, y_train_all, y_test = train_test_split(spam_X, spam_y, test_size=0.2)\n",
    "\n",
    "# Fit StandardScaler only on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_all = scaler.fit_transform(X_train_all)\n",
    "\n",
    "# Transform test data with the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "827aca90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition 0.2 Results:\n",
      "  Random Forest - Train Accuracy: 0.9995471014492754, Val Accuracy: 0.9560688405797101, Test Accuracy: 0.957608695652174\n",
      "  SVM - Train Accuracy: 0.927536231884058, Val Accuracy: 0.9207427536231885, Test Accuracy: 0.938768115942029\n",
      "  Neural Network - Train Accuracy: 0.9329710205396017, Val Accuracy: 0.9257246255874634, Test Accuracy: 0.9402173757553101\n",
      "Partition 0.5 Results:\n",
      "  Random Forest - Train Accuracy: 0.9998188405797102, Val Accuracy: 0.951268115942029, Test Accuracy: 0.9554347826086956\n",
      "  SVM - Train Accuracy: 0.9271739130434783, Val Accuracy: 0.9208333333333334, Test Accuracy: 0.9391304347826087\n",
      "  Neural Network - Train Accuracy: 0.9202898542086283, Val Accuracy: 0.9170289834340414, Test Accuracy: 0.9333333373069763\n",
      "Partition 0.8 Results:\n",
      "  Random Forest - Train Accuracy: 1.0, Val Accuracy: 0.9387454710144927, Test Accuracy: 0.9485507246376811\n",
      "  SVM - Train Accuracy: 0.9302536231884058, Val Accuracy: 0.9108922101449276, Test Accuracy: 0.928623188405797\n",
      "  Neural Network - Train Accuracy: 0.8903985420862833, Val Accuracy: 0.8816802700360616, Test Accuracy: 0.9014492829640707\n"
     ]
    }
   ],
   "source": [
    "for partition in partitions:\n",
    "    rf_train_accuracies, rf_val_accuracies, rf_test_accuracies = [], [], []\n",
    "    svm_train_accuracies, svm_val_accuracies, svm_test_accuracies = [], [], []\n",
    "    nn_train_accuracies, nn_val_accuracies, nn_test_accuracies = [], [], []\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        X_train_scaled, X_val_scaled, y_train, y_val = train_test_split(X_train_scaled_all, y_train_all, test_size=partition)\n",
    "        \n",
    "        # Random Forest\n",
    "        rf_model = RandomForestClassifier(**best_params_rf, verbose = 0)\n",
    "        rf_model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        rf_train_accuracy = rf_model.score(X_train_scaled, y_train)\n",
    "        rf_val_accuracy = rf_model.score(X_val_scaled, y_val)\n",
    "        rf_test_accuracy = rf_model.score(X_test_scaled, y_test)\n",
    "        \n",
    "        rf_train_accuracies.append(rf_train_accuracy)\n",
    "        rf_val_accuracies.append(rf_val_accuracy)\n",
    "        rf_test_accuracies.append(rf_test_accuracy)\n",
    "\n",
    "        # SVM\n",
    "        svm_model = SVC(**best_params_svm, probability = True)\n",
    "        svm_model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        svm_train_accuracy = svm_model.score(X_train_scaled, y_train)\n",
    "        svm_val_accuracy = svm_model.score(X_val_scaled, y_val)\n",
    "        svm_test_accuracy = svm_model.score(X_test_scaled, y_test)\n",
    "        \n",
    "        svm_train_accuracies.append(svm_train_accuracy)\n",
    "        svm_val_accuracies.append(svm_val_accuracy)\n",
    "        svm_test_accuracies.append(svm_test_accuracy)\n",
    "\n",
    "        # Neural Network\n",
    "        nn_model = create_model(**best_params_nn)\n",
    "        nn_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "        nn_model.fit(X_train_scaled, y_train, epochs = 5, batch_size = 32, verbose = 0)\n",
    "        \n",
    "        nn_loss_train, nn_accuracy_train = nn_model.evaluate(X_train_scaled, y_train, verbose = 0)\n",
    "        nn_loss_val, nn_accuracy_val = nn_model.evaluate(X_val_scaled, y_val, verbose = 0)\n",
    "        nn_loss_test, nn_accuracy_test = nn_model.evaluate(X_test_scaled, y_test, verbose = 0)\n",
    "        \n",
    "        nn_train_accuracies.append(nn_accuracy_train)\n",
    "        nn_val_accuracies.append(nn_accuracy_val)\n",
    "        nn_test_accuracies.append(nn_accuracy_test)\n",
    "\n",
    "    # Calculate mean accuracies for Random Forest\n",
    "    rf_mean_train_accuracy = np.mean(rf_train_accuracies)\n",
    "    rf_mean_val_accuracy = np.mean(rf_val_accuracies)\n",
    "    rf_mean_test_accuracy = np.mean(rf_test_accuracies)\n",
    "\n",
    "    # Calculate mean accuracies for SVM\n",
    "    svm_mean_train_accuracy = np.mean(svm_train_accuracies)\n",
    "    svm_mean_val_accuracy = np.mean(svm_val_accuracies)\n",
    "    svm_mean_test_accuracy = np.mean(svm_test_accuracies)\n",
    "\n",
    "    # Calculate mean accuracies for Neural Network\n",
    "    nn_mean_train_accuracy = np.mean(nn_train_accuracies)\n",
    "    nn_mean_val_accuracy = np.mean(nn_val_accuracies)\n",
    "    nn_mean_test_accuracy = np.mean(nn_test_accuracies)\n",
    "\n",
    "    # Print the results in an organized manner\n",
    "    print(f\"Partition {partition} Results:\")\n",
    "    print(f\"  Random Forest - Train Accuracy: {rf_mean_train_accuracy}, Val Accuracy: {rf_mean_val_accuracy}, Test Accuracy: {rf_mean_test_accuracy}\")\n",
    "    print(f\"  SVM - Train Accuracy: {svm_mean_train_accuracy}, Val Accuracy: {svm_mean_val_accuracy}, Test Accuracy: {svm_mean_test_accuracy}\")\n",
    "    print(f\"  Neural Network - Train Accuracy: {nn_mean_train_accuracy}, Val Accuracy: {nn_mean_val_accuracy}, Test Accuracy: {nn_mean_test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ca7d8",
   "metadata": {},
   "source": [
    "# table for summary accuracy of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b0102f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Train/Test Split</th>\n",
       "      <th>Training Acc</th>\n",
       "      <th>Validation Acc</th>\n",
       "      <th>Testing Acc</th>\n",
       "      <th>Hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>0.9632</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>0.8795</td>\n",
       "      <td>0.8575</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Classifier Train/Test Split  Training Acc  Validation Acc  Testing Acc  \\\n",
       "0   Random Forest          0.8/0.2        1.0000          1.0000       1.0000   \n",
       "1   Random Forest          0.5/0.5        1.0000          1.0000       1.0000   \n",
       "2   Random Forest          0.2/0.8        1.0000          0.9990       0.9997   \n",
       "3             SVM          0.8/0.2        1.0000          1.0000       1.0000   \n",
       "4             SVM          0.5/0.5        1.0000          1.0000       1.0000   \n",
       "5             SVM          0.2/0.8        1.0000          1.0000       1.0000   \n",
       "6  Neural Network          0.8/0.2        0.9964          0.9970       0.9973   \n",
       "7  Neural Network          0.5/0.5        0.9701          0.9632       0.9680   \n",
       "8  Neural Network          0.2/0.8        0.8795          0.8575       0.8650   \n",
       "\n",
       "                              Hyperparameters  \n",
       "0           max_features=1, n_estimators=1024  \n",
       "1           max_features=1, n_estimators=1024  \n",
       "2           max_features=1, n_estimators=1024  \n",
       "3           C=0.1, gamma=0.001, kernel=linear  \n",
       "4           C=0.1, gamma=0.001, kernel=linear  \n",
       "5           C=0.1, gamma=0.001, kernel=linear  \n",
       "6  model__hidden_units=2, model__momentum=0.9  \n",
       "7  model__hidden_units=2, model__momentum=0.9  \n",
       "8  model__hidden_units=2, model__momentum=0.9  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Truncating accuracies to 4 decimal places and creating summarized tables for each dataset\n",
    "def truncate_accuracies(accuracies):\n",
    "    return {k: [round(v, 4) for v in values] for k, values in accuracies.items()}\n",
    "\n",
    "# Truncated accuracies for each dataset\n",
    "wine_accuracies = {\n",
    "    \"Random Forest\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9990, 0.9997],\n",
    "    \"SVM\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "    \"Neural Network\": [0.9964, 0.9970, 0.9973, 0.9701, 0.9632, 0.9680, 0.8795, 0.8575, 0.8650]\n",
    "}\n",
    "\n",
    "students_accuracies = {\n",
    "    \"Random Forest\": [1.0, 0.9007, 0.8765, 1.0, 0.8981, 0.8760, 1.0, 0.8880, 0.8471],\n",
    "    \"SVM\": [0.9209, 0.9076, 0.9036, 0.9208, 0.9079, 0.8990, 0.9190, 0.9007, 0.8815],\n",
    "    \"Neural Network\": [0.9136, 0.9002, 0.8737, 0.9112, 0.8933, 0.8655, 0.8603, 0.8442, 0.8072]\n",
    "}\n",
    "\n",
    "spam_accuracies = {\n",
    "    \"Random Forest\": [0.9998, 0.9570, 0.9540, 0.9996, 0.9487, 0.9464, 1.0, 0.9428, 0.9417],\n",
    "    \"SVM\": [0.9286, 0.9343, 0.9337, 0.9299, 0.9165, 0.9293, 0.9321, 0.9134, 0.9163],\n",
    "    \"Neural Network\": [0.9331, 0.9348, 0.9290, 0.9246, 0.9138, 0.9196, 0.8832, 0.8757, 0.8819]\n",
    "}\n",
    "# Extracting the best hyperparameters from the provided code\n",
    "best_params_rf = {'max_features': 1, 'n_estimators': 1024}\n",
    "best_params_svm = {'C': 0.1, 'gamma': 0.001, 'kernel': 'linear'}\n",
    "best_params_nn = {'model__hidden_units': 2, 'model__momentum': 0.9}\n",
    "\n",
    "# Function to create a combined table for a dataset with hyperparameters included\n",
    "def create_combined_table_with_hyperparams(accuracies, dataset_name, hyperparameters):\n",
    "    # Extracting accuracies for each classifier and split\n",
    "    data = []\n",
    "    splits = ['0.8/0.2', '0.5/0.5', '0.2/0.8']  # Train/Test splits\n",
    "    for classifier, acc_values in accuracies.items():\n",
    "        hyperparams_str = ', '.join([f\"{k}={v}\" for k, v in hyperparameters[classifier].items()])\n",
    "        for i, split in enumerate(splits):  # Processing each Train/Val/Test set\n",
    "            train_acc = acc_values[i * 3]\n",
    "            val_acc = acc_values[i * 3 + 1]\n",
    "            test_acc = acc_values[i * 3 + 2]\n",
    "            data.append([classifier, split, train_acc, val_acc, test_acc, hyperparams_str])\n",
    "\n",
    "    # Creating the DataFrame\n",
    "    columns = ['Classifier', 'Train/Test Split', 'Training Acc', 'Validation Acc', 'Testing Acc', 'Hyperparameters']\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Hyperparameters dictionary for each classifier\n",
    "hyperparameters = {\n",
    "    'Random Forest': best_params_rf,\n",
    "    'SVM': best_params_svm,\n",
    "    'Neural Network': best_params_nn\n",
    "}\n",
    "\n",
    "# Creating combined tables with hyperparameters for each dataset\n",
    "combined_wine = create_combined_table_with_hyperparams(wine_accuracies, \"Wine\", hyperparameters)\n",
    "combined_students = create_combined_table_with_hyperparams(students_accuracies, \"Students\", hyperparameters)\n",
    "combined_spam = create_combined_table_with_hyperparams(spam_accuracies, \"Spam\", hyperparameters)\n",
    "\n",
    "# Displaying the corrected combined table with hyperparameters for the Wine dataset\n",
    "combined_wine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "35557c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Train/Test Split</th>\n",
       "      <th>Training Acc</th>\n",
       "      <th>Validation Acc</th>\n",
       "      <th>Testing Acc</th>\n",
       "      <th>Hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9007</td>\n",
       "      <td>0.8765</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8981</td>\n",
       "      <td>0.8760</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.9076</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>0.9208</td>\n",
       "      <td>0.9079</td>\n",
       "      <td>0.8990</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>0.9190</td>\n",
       "      <td>0.9007</td>\n",
       "      <td>0.8815</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.9002</td>\n",
       "      <td>0.8737</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>0.9112</td>\n",
       "      <td>0.8933</td>\n",
       "      <td>0.8655</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>0.8603</td>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.8072</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Classifier Train/Test Split  Training Acc  Validation Acc  Testing Acc  \\\n",
       "0   Random Forest          0.8/0.2        1.0000          0.9007       0.8765   \n",
       "1   Random Forest          0.5/0.5        1.0000          0.8981       0.8760   \n",
       "2   Random Forest          0.2/0.8        1.0000          0.8880       0.8471   \n",
       "3             SVM          0.8/0.2        0.9209          0.9076       0.9036   \n",
       "4             SVM          0.5/0.5        0.9208          0.9079       0.8990   \n",
       "5             SVM          0.2/0.8        0.9190          0.9007       0.8815   \n",
       "6  Neural Network          0.8/0.2        0.9136          0.9002       0.8737   \n",
       "7  Neural Network          0.5/0.5        0.9112          0.8933       0.8655   \n",
       "8  Neural Network          0.2/0.8        0.8603          0.8442       0.8072   \n",
       "\n",
       "                              Hyperparameters  \n",
       "0           max_features=1, n_estimators=1024  \n",
       "1           max_features=1, n_estimators=1024  \n",
       "2           max_features=1, n_estimators=1024  \n",
       "3           C=0.1, gamma=0.001, kernel=linear  \n",
       "4           C=0.1, gamma=0.001, kernel=linear  \n",
       "5           C=0.1, gamma=0.001, kernel=linear  \n",
       "6  model__hidden_units=2, model__momentum=0.9  \n",
       "7  model__hidden_units=2, model__momentum=0.9  \n",
       "8  model__hidden_units=2, model__momentum=0.9  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c6d6632e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Train/Test Split</th>\n",
       "      <th>Training Acc</th>\n",
       "      <th>Validation Acc</th>\n",
       "      <th>Testing Acc</th>\n",
       "      <th>Hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.9570</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.9487</td>\n",
       "      <td>0.9464</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9428</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>0.9343</td>\n",
       "      <td>0.9337</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>0.9299</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>0.9293</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>0.9321</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>0.9163</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.9348</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>0.9246</td>\n",
       "      <td>0.9138</td>\n",
       "      <td>0.9196</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>0.8832</td>\n",
       "      <td>0.8757</td>\n",
       "      <td>0.8819</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Classifier Train/Test Split  Training Acc  Validation Acc  Testing Acc  \\\n",
       "0   Random Forest          0.8/0.2        0.9998          0.9570       0.9540   \n",
       "1   Random Forest          0.5/0.5        0.9996          0.9487       0.9464   \n",
       "2   Random Forest          0.2/0.8        1.0000          0.9428       0.9417   \n",
       "3             SVM          0.8/0.2        0.9286          0.9343       0.9337   \n",
       "4             SVM          0.5/0.5        0.9299          0.9165       0.9293   \n",
       "5             SVM          0.2/0.8        0.9321          0.9134       0.9163   \n",
       "6  Neural Network          0.8/0.2        0.9331          0.9348       0.9290   \n",
       "7  Neural Network          0.5/0.5        0.9246          0.9138       0.9196   \n",
       "8  Neural Network          0.2/0.8        0.8832          0.8757       0.8819   \n",
       "\n",
       "                              Hyperparameters  \n",
       "0           max_features=1, n_estimators=1024  \n",
       "1           max_features=1, n_estimators=1024  \n",
       "2           max_features=1, n_estimators=1024  \n",
       "3           C=0.1, gamma=0.001, kernel=linear  \n",
       "4           C=0.1, gamma=0.001, kernel=linear  \n",
       "5           C=0.1, gamma=0.001, kernel=linear  \n",
       "6  model__hidden_units=2, model__momentum=0.9  \n",
       "7  model__hidden_units=2, model__momentum=0.9  \n",
       "8  model__hidden_units=2, model__momentum=0.9  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "75d9de0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Train/Test Split</th>\n",
       "      <th>Training Acc</th>\n",
       "      <th>Validation Acc</th>\n",
       "      <th>Testing Acc</th>\n",
       "      <th>Hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wine</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wine</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wine</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>0.9632</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>0.8795</td>\n",
       "      <td>0.8575</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Students</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9007</td>\n",
       "      <td>0.8765</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Students</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8981</td>\n",
       "      <td>0.8760</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Students</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Students</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.9076</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Students</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>0.9208</td>\n",
       "      <td>0.9079</td>\n",
       "      <td>0.8990</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Students</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>0.9190</td>\n",
       "      <td>0.9007</td>\n",
       "      <td>0.8815</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Students</td>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.9002</td>\n",
       "      <td>0.8737</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Students</td>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>0.9112</td>\n",
       "      <td>0.8933</td>\n",
       "      <td>0.8655</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Students</td>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>0.8603</td>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.8072</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spam</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.9570</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spam</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.9487</td>\n",
       "      <td>0.9464</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spam</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9428</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>max_features=1, n_estimators=1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spam</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>0.9343</td>\n",
       "      <td>0.9337</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spam</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>0.9299</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>0.9293</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spam</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>0.9321</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>0.9163</td>\n",
       "      <td>C=0.1, gamma=0.001, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spam</td>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.8/0.2</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.9348</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Spam</td>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.5/0.5</td>\n",
       "      <td>0.9246</td>\n",
       "      <td>0.9138</td>\n",
       "      <td>0.9196</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Spam</td>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.2/0.8</td>\n",
       "      <td>0.8832</td>\n",
       "      <td>0.8757</td>\n",
       "      <td>0.8819</td>\n",
       "      <td>model__hidden_units=2, model__momentum=0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset      Classifier Train/Test Split  Training Acc  Validation Acc  \\\n",
       "0      Wine   Random Forest          0.8/0.2        1.0000          1.0000   \n",
       "1      Wine   Random Forest          0.5/0.5        1.0000          1.0000   \n",
       "2      Wine   Random Forest          0.2/0.8        1.0000          0.9990   \n",
       "3      Wine             SVM          0.8/0.2        1.0000          1.0000   \n",
       "4      Wine             SVM          0.5/0.5        1.0000          1.0000   \n",
       "5      Wine             SVM          0.2/0.8        1.0000          1.0000   \n",
       "6      Wine  Neural Network          0.8/0.2        0.9964          0.9970   \n",
       "7      Wine  Neural Network          0.5/0.5        0.9701          0.9632   \n",
       "8      Wine  Neural Network          0.2/0.8        0.8795          0.8575   \n",
       "0  Students   Random Forest          0.8/0.2        1.0000          0.9007   \n",
       "1  Students   Random Forest          0.5/0.5        1.0000          0.8981   \n",
       "2  Students   Random Forest          0.2/0.8        1.0000          0.8880   \n",
       "3  Students             SVM          0.8/0.2        0.9209          0.9076   \n",
       "4  Students             SVM          0.5/0.5        0.9208          0.9079   \n",
       "5  Students             SVM          0.2/0.8        0.9190          0.9007   \n",
       "6  Students  Neural Network          0.8/0.2        0.9136          0.9002   \n",
       "7  Students  Neural Network          0.5/0.5        0.9112          0.8933   \n",
       "8  Students  Neural Network          0.2/0.8        0.8603          0.8442   \n",
       "0      Spam   Random Forest          0.8/0.2        0.9998          0.9570   \n",
       "1      Spam   Random Forest          0.5/0.5        0.9996          0.9487   \n",
       "2      Spam   Random Forest          0.2/0.8        1.0000          0.9428   \n",
       "3      Spam             SVM          0.8/0.2        0.9286          0.9343   \n",
       "4      Spam             SVM          0.5/0.5        0.9299          0.9165   \n",
       "5      Spam             SVM          0.2/0.8        0.9321          0.9134   \n",
       "6      Spam  Neural Network          0.8/0.2        0.9331          0.9348   \n",
       "7      Spam  Neural Network          0.5/0.5        0.9246          0.9138   \n",
       "8      Spam  Neural Network          0.2/0.8        0.8832          0.8757   \n",
       "\n",
       "   Testing Acc                             Hyperparameters  \n",
       "0       1.0000           max_features=1, n_estimators=1024  \n",
       "1       1.0000           max_features=1, n_estimators=1024  \n",
       "2       0.9997           max_features=1, n_estimators=1024  \n",
       "3       1.0000           C=0.1, gamma=0.001, kernel=linear  \n",
       "4       1.0000           C=0.1, gamma=0.001, kernel=linear  \n",
       "5       1.0000           C=0.1, gamma=0.001, kernel=linear  \n",
       "6       0.9973  model__hidden_units=2, model__momentum=0.9  \n",
       "7       0.9680  model__hidden_units=2, model__momentum=0.9  \n",
       "8       0.8650  model__hidden_units=2, model__momentum=0.9  \n",
       "0       0.8765           max_features=1, n_estimators=1024  \n",
       "1       0.8760           max_features=1, n_estimators=1024  \n",
       "2       0.8471           max_features=1, n_estimators=1024  \n",
       "3       0.9036           C=0.1, gamma=0.001, kernel=linear  \n",
       "4       0.8990           C=0.1, gamma=0.001, kernel=linear  \n",
       "5       0.8815           C=0.1, gamma=0.001, kernel=linear  \n",
       "6       0.8737  model__hidden_units=2, model__momentum=0.9  \n",
       "7       0.8655  model__hidden_units=2, model__momentum=0.9  \n",
       "8       0.8072  model__hidden_units=2, model__momentum=0.9  \n",
       "0       0.9540           max_features=1, n_estimators=1024  \n",
       "1       0.9464           max_features=1, n_estimators=1024  \n",
       "2       0.9417           max_features=1, n_estimators=1024  \n",
       "3       0.9337           C=0.1, gamma=0.001, kernel=linear  \n",
       "4       0.9293           C=0.1, gamma=0.001, kernel=linear  \n",
       "5       0.9163           C=0.1, gamma=0.001, kernel=linear  \n",
       "6       0.9290  model__hidden_units=2, model__momentum=0.9  \n",
       "7       0.9196  model__hidden_units=2, model__momentum=0.9  \n",
       "8       0.8819  model__hidden_units=2, model__momentum=0.9  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining the summary tables for all datasets into one table\n",
    "combined_summary_all = pd.concat([combined_wine, \n",
    "                                  combined_students, \n",
    "                                  combined_spam], \n",
    "                                 keys=['Wine', 'Students', 'Spam'], \n",
    "                                 axis=0).reset_index(level=0).rename(columns={'level_0': 'Dataset'})\n",
    "\n",
    "# Displaying the combined summary table for all datasets\n",
    "combined_summary_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "412ed1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Function to plot accuracies using a grouped bar chart for each classifier in a dataset\n",
    "def plot_grouped_bar_accuracies(df, dataset_name):\n",
    "    # Melting DataFrame for easier plotting\n",
    "    melted_df = df.melt(id_vars=['Classifier', 'Train/Test Split'], \n",
    "                        value_vars=['Training Acc', 'Validation Acc', 'Testing Acc'],\n",
    "                        var_name='Accuracy Type', value_name='Accuracy')\n",
    "\n",
    "    # Setting up the plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Train/Test Split', y='Accuracy', hue='Accuracy Type', data=melted_df, \n",
    "                palette='viridis', edgecolor='black')\n",
    "\n",
    "    # Finalizing the plot\n",
    "    plt.title(f'Accuracies for {dataset_name} Dataset')\n",
    "    plt.xlabel('Train/Test Split')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(title='Accuracy Type')\n",
    "    plt.ylim(0, 1.05)  # Set y-axis limit to show all bars clearly\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plotting grouped bar chart accuracy charts for each dataset\n",
    "plot_grouped_bar_accuracies(combined_wine, 'Wine')\n",
    "plot_grouped_bar_accuracies(combined_students, 'Students')\n",
    "plot_grouped_bar_accuracies(combined_spam, 'Spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9975ef",
   "metadata": {},
   "source": [
    "## White wine\n",
    "Partition 0.2 Results:\n",
    "  Random Forest - Train Accuracy: 1.0, Val Accuracy: 1.0, Test Accuracy: 1.0\n",
    "  SVM - Train Accuracy: 1.0, Val Accuracy: 1.0, Test Accuracy: 1.0\n",
    "  Neural Network - Train Accuracy: 0.9963837663332621, Val Accuracy: 0.9970238010088602, Test Accuracy: 0.9972789287567139\n",
    "Partition 0.5 Results:\n",
    "  Random Forest - Train Accuracy: 1.0, Val Accuracy: 1.0, Test Accuracy: 1.0\n",
    "  SVM - Train Accuracy: 1.0, Val Accuracy: 1.0, Test Accuracy: 1.0\n",
    "  Neural Network - Train Accuracy: 0.9700527588526408, Val Accuracy: 0.9632465442021688, Test Accuracy: 0.9680272142092387\n",
    "Partition 0.8 Results:\n",
    "  Random Forest - Train Accuracy: 1.0, Val Accuracy: 0.9990430622009571, Test Accuracy: 0.9996598639455782\n",
    "  SVM - Train Accuracy: 1.0, Val Accuracy: 1.0, Test Accuracy: 1.0\n",
    "  Neural Network - Train Accuracy: 0.8795231978098551, Val Accuracy: 0.8575225869814554, Test Accuracy: 0.8649659951527914"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839ebfbd",
   "metadata": {},
   "source": [
    "## students\n",
    "\n",
    "Partition 0.2 Results:\n",
    "  Random Forest - Train Accuracy: 1.0, Val Accuracy: 0.9007458405048766, Test Accuracy: 0.8764921946740128\n",
    "  SVM - Train Accuracy: 0.9209355718180513, Val Accuracy: 0.9076305220883533, Test Accuracy: 0.9035812672176308\n",
    "  Neural Network - Train Accuracy: 0.9136174519856771, Val Accuracy: 0.9001721143722534, Test Accuracy: 0.8737373550732931\n",
    "Partition 0.5 Results:\n",
    "  Random Forest - Train Accuracy: 1.0, Val Accuracy: 0.8980716253443526, Test Accuracy: 0.8760330578512395\n",
    "  SVM - Train Accuracy: 0.9207988980716254, Val Accuracy: 0.9079430670339761, Test Accuracy: 0.8989898989898989\n",
    "  Neural Network - Train Accuracy: 0.9111570119857788, Val Accuracy: 0.8932506839434305, Test Accuracy: 0.8654729127883911\n",
    "Partition 0.8 Results:\n",
    "  Random Forest - Train Accuracy: 1.0, Val Accuracy: 0.8879804934021802, Test Accuracy: 0.847107438016529\n",
    "  SVM - Train Accuracy: 0.9189655172413792, Val Accuracy: 0.9007458405048766, Test Accuracy: 0.8815426997245179\n",
    "  Neural Network - Train Accuracy: 0.8603448470433553, Val Accuracy: 0.8442340691884359, Test Accuracy: 0.8071625431378683"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b519e1e",
   "metadata": {},
   "source": [
    "## spam\n",
    "\n",
    "Partition 0.2 Results:\n",
    "  Random Forest - Train Accuracy: 0.9997735507246377, Val Accuracy: 0.9569746376811595, Test Accuracy: 0.9539855072463768\n",
    "  SVM - Train Accuracy: 0.9285552536231885, Val Accuracy: 0.9343297101449276, Test Accuracy: 0.9336956521739129\n",
    "  Neural Network - Train Accuracy: 0.93308424949646, Val Accuracy: 0.9347826242446899, Test Accuracy: 0.9289855162302653\n",
    "Partition 0.5 Results:\n",
    "  Random Forest - Train Accuracy: 0.9996376811594203, Val Accuracy: 0.9487318840579709, Test Accuracy: 0.946376811594203\n",
    "  SVM - Train Accuracy: 0.9298913043478261, Val Accuracy: 0.9164855072463768, Test Accuracy: 0.9293478260869565\n",
    "  Neural Network - Train Accuracy: 0.9246376951535543, Val Accuracy: 0.9137681126594543, Test Accuracy: 0.919565220673879\n",
    "Partition 0.8 Results:\n",
    "  Random Forest - Train Accuracy: 1.0, Val Accuracy: 0.9428215579710146, Test Accuracy: 0.9416666666666668\n",
    "  SVM - Train Accuracy: 0.9320652173913043, Val Accuracy: 0.9133831521739131, Test Accuracy: 0.9163043478260869\n",
    "  Neural Network - Train Accuracy: 0.88315216700236, Val Accuracy: 0.8756793340047201, Test Accuracy: 0.8818840583165487"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
